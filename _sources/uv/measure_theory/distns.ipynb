{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deadly-return",
   "metadata": {},
   "source": [
    "(uv:mt:distns)=\n",
    "\n",
    "# Distribution Functions\n",
    "\n",
    "So, now we have these concepts called random variables, which are really just measurable functions on a particular domain with respect to some codomain. We can perform all of the traditional mathematical operations with random variables, and still obtain random variables. What else do we need as far as machinery goes? We need to link these random variables to probabilities. This happens via the distribution function.\n",
    "\n",
    "## Inducing distribution functions\n",
    "\n",
    "Now that we have random variables (measurable functions), if the domain is a probability space, we can use the definition of a random variable to deduce that it is certainly the case that for any set in the codomain, the preimage of the set in the codomain is in the $\\sigma$-algebra of the corresponding probability space. Since this set is in the $\\sigma$-algebra of the probability space, we can assign a probability to that set:\n",
    "\n",
    "````{prf:definition} Law of a random variable\n",
    ":label: uv:mt:distns:law\n",
    "Suppose the probability space $(\\Omega, \\mathcal F, \\mathbb P)$ and the measurable space $(S, \\Sigma)$, where $X \\in m(\\mathcal F, \\Sigma)$ is a random variable. Then the induced probability measure on $S$ by $X$, also known as the *law* of $X$, is the measure $\\mathcal L_X$ where for every $B \\in \\Sigma$:\n",
    "```{math}\n",
    "    \\mathcal L_X(B) &\\triangleq \\mathbb P\\left(\\{\\omega : X(\\omega) \\in B\\}\\right) \\\\\n",
    "    &\\equiv \\mathbb P\\left(X^{-1}(B)\\right) \\\\\n",
    "    &\\equiv \\mathbb P(X \\in B)\n",
    "```\n",
    "````\n",
    "The idea here is that we are, in some sense, finding which values of $\\Omega$ were mapped into $B$ by $X$ via $X^{-1}(B)$ (which must be a set $F \\in \\mathcal F$, by definition of a random variable), and then calculating the probability (via $\\mathbb P$) of this set. Since $\\mathbb P$ is a probability measure with respect to the measurable space $(\\Omega, \\mathcal F)$, this is a possible thing that we can do. We call this particular induced probability measure the *law* of $X$ because, as we will see shortly, it ascribes most of the behaviors about $X$ that we will care about.\n",
    "\n",
    "Let's consider this from another angle to describe what's going on here. First, we know that $X : \\Omega \\rightarrow S$; that is, $X$ is mapping elements of the event space to the codomain. $X^{-1} : \\Sigma \\rightarrow \\mathcal F$ (the definition of a $(\\mathcal F, \\Sigma)$-random variable) takes us from subsets of the codomain (elements of $\\Sigma$) to measurable subsets of the sample space (elements of $\\mathcal F$). We can then use $\\mathbb P$ to measure these measurable subsets of the sample space.\n",
    "\n",
    "In other words, using compositions, we could describe $\\mathcal L_X \\triangleq \\mathbb P \\circ X^{-1}$. $\\mathcal L_X$ represents the probability that under $X$, a draw from the event space $\\omega$ winds up in $B$. From the definition, it should be pretty clear that $\\mathcal L_X$ is a probability measure on the measurable space $(S, \\Sigma)$:\n",
    "\n",
    "````{prf:proposition} The law is a probability measure\n",
    ":label: uv:mt:distns:law_is_meas\n",
    "Suppose the probability space $(\\Omega, \\mathcal F, \\mathbb P)$ and the measurable space $(S, \\Sigma)$, where $X \\in m(\\mathcal F, \\Sigma)$ is a random variable, and $\\mathcal L_X = \\mathbb P\\circ X^{-1}$ is the law of $X$. $\\mathcal L_X$ is a probability measure on $(S, \\Sigma)$.\n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "1\\. $\\mathcal L_X(B) \\geq 0$ for every $B \\in \\Sigma$: Suppose that $B \\in \\Sigma$. Then:\n",
    "```{math}\n",
    "    \\mathcal L_X(B) &= \\mathbb P(X \\in B) \\equiv \\mathbb P(\\{\\omega : X(\\omega) \\in B\\}) \\\\\n",
    "    &\\geq 0\n",
    "```\n",
    "since $\\mathbb P$ is a probability measure.\n",
    "\n",
    "2\\. $\\mathcal L_X(S) = 1$: \n",
    "```{math}\n",
    "    \\mathcal L_X(S) &= \\mathbb P(X \\in S) \\equiv \\mathbb P(\\{\\omega : X(\\omega) \\in S\\}) \\\\\n",
    "    &= 1\n",
    "```\n",
    "which follows because $X : \\omega \\mapsto X(\\omega) \\in S$ for any $\\omega$ by definition of $X : \\Omega \\rightarrow S$.\n",
    "\n",
    "3\\. Countably additive: Suppose that $(B_n)_{n \\in \\mathbb N} \\subseteq \\Sigma$ are disjoint. Since $\\Sigma$ is a $\\sigma$-algebra, then $B = \\bigcup_{n \\in \\mathbb N}B_n \\in \\Sigma$, and:\n",
    "```{math}\n",
    "    \\mathcal L_X(B) &= \\mathcal L_X\\left(\\bigcup_{n \\in \\mathbb N}B_n\\right) \\\\\n",
    "    &= \\mathbb P\\left(X \\in \\bigcup_{n \\in \\mathbb N}B_n\\right) \\equiv  P\\left(\\left\\{\\omega : X(\\omega) \\in \\bigcup_{n \\in \\mathbb N}B_n\\right\\}\\right) \\\\\n",
    "    &= \\mathbb P\\left(\\bigcup_{n \\in \\mathbb N}(X \\in B_n)\\right) \\equiv \\mathbb P\\left(\\bigcup_{n \\in \\mathbb N}\\{\\omega : X(\\omega) \\in B_n\\}\\right),\\,\\,\\,\\,\\text{defn. of union}\n",
    "```\n",
    "As $X$ is a function, each $X^{-1}(B_n)$ are disjoint because $X$ can only map each $\\omega$ to one value in $S$. Therefore, we can use the countable additivity of $\\mathbb P$:\n",
    "```{math}\n",
    "    \\mathcal L_X(B) &= \\sum_{n \\in \\mathbb N}\\mathbb P(X \\in B_n) \\equiv \\sum_{n \\in \\mathbb N}\\mathbb P(\\{\\omega : X(\\omega) \\in B_n\\}),\\,\\,\\,\\,\\text{countable additivity of }\\mathbb P \\\\\n",
    "    &= \\sum_{n \\in \\mathbb N}\\mathcal L_X(B_n).\n",
    "```\n",
    "Since $\\mathcal L_X : \\mathcal \\Sigma \\rightarrow [0, 1]$, $\\mathcal L_X(S) = 1$, and is countably additive, it is a probability measure.\n",
    "````\n",
    "\n",
    "If the codomain is the measurable space $(\\mathbb R, \\mathcal R)$, we are ready to make a further claim about $\\mathcal L_X$ using the distribution function:\n",
    "\n",
    "````{prf:definition} Distribution function\n",
    ":label: uv:mt:distns:distn_fn\n",
    "Suppose that $(\\Omega, \\mathcal F, \\mathbb P)$ is a probability space, and the measurable space $(\\mathbb R, \\mathcal R)$, where $X \\in m(\\mathcal F, \\mathcal R)$ is a random variable with law $\\mathcal L_X$. The distribution function is:\n",
    "```{math}\n",
    "    F_X(c) \\triangleq \\mathcal L_X((-\\infty, c]) \\equiv \\mathbb P(X \\leq c) \\equiv \\mathbb P\\left(\\omega \\in \\Omega : X(\\omega) \\leq c\\right).\n",
    "```\n",
    "````\n",
    "\n",
    "As it turns out, the distribution function *fully determines* the law:\n",
    "\n",
    "````{prf:theorem} The distribution function fully determines the law of a random variable\n",
    ":label: uv:mt:distns:distn_fn_dets_law\n",
    "Suppose that $(\\Omega, \\mathcal F, \\mathbb P)$ is a probability space, and the measurable space $(\\mathbb R, \\mathcal R)$, where $X \\in m(\\mathcal F, \\mathcal R)$ is a random variable. Then $\\mathcal L_X$ is fully determined by the function $F_X : \\mathbb R \\rightarrow [0, 1]$.\n",
    "````\n",
    "````{prf:proof}\n",
    "Note that $\\mathcal P = \\left\\{(-\\infty, c] : c \\in \\mathbb R\\right\\}$ is a $\\pi$-system on $\\mathbb R$, where $\\sigma(\\mathcal P) = \\mathcal R$.\n",
    "\n",
    "Further, note that on $\\mathcal P$, that for any $c$, $\\mathcal L((-\\infty, c]) = F_X(c)$, by definition, so $\\mathcal L_X$ and $F_X$ agree on all of $\\mathcal P$.\n",
    "\n",
    "Then by {prf:ref}`uv:mt:prob_spaces:meas:unique`, $\\mathcal L_X = F_X$ on $\\sigma(\\mathcal P) = \\mathcal R$. \n",
    "````\n",
    "\n",
    "In general, when we work with random variables, we will work with the distribution function for many of our proofs that we consider. \n",
    "\n",
    "````{prf:remark} The codomain will be $(\\mathbb R, \\mathcal R)$\n",
    "For the remainder of this section, we will work where the codomain is the measurable space $(\\mathbb R, \\mathcal R)$. For this reason, we'll omit explicitly stating the codomain every single time for brevity.\n",
    "````\n",
    "\n",
    "## Properties of distribution functions\n",
    "\n",
    "Distribution functions have some nice properties that will be convenient for building up intuition about the law of random variables. First up is monotonicity:\n",
    "\n",
    "````{prf:property} Monotonicity of distribution functions\n",
    "Suppose the probability space $(\\Omega, \\mathcal F, \\mathbb P)$, and that $X \\in m\\mathcal F$ is a random variable with distribution function $F$. Then if $x \\leq y \\in \\mathbb R$, $F(x) \\leq F(y)$.\n",
    "````\n",
    "````{prf:proof}\n",
    "Since $x \\leq y$, then:\n",
    "```{math}\n",
    "    \\{\\omega : X(\\omega) \\leq x\\} \\equiv \\{X \\leq x\\} \\subseteq \\{X \\leq y\\} \\equiv \\{\\omega : X(\\omega) \\leq y\\}\n",
    "```\n",
    "Then since $\\mathbb P$ is a measure, {prf:ref}`uv:mt:prob_spaces:meas:monotone`, $F(x) \\equiv \\mathbb P(X \\leq x) \\leq \\mathbb P(X \\leq y) \\equiv F(y)$. \n",
    "````\n",
    "\n",
    "So, what this establishes is that $F$ is monotone non-decreasing. Further, we can establish properties about the tails of $F$, too. These results borrow the monotone convergence (from above and below) of measures:\n",
    "\n",
    "````{prf:property} Tails of the distribution function\n",
    "Suppose the probability space $(\\Omega, \\mathcal F, \\mathbb P)$, and that $X \\in m\\mathcal F$ is a random variable with distribution function $F$. Then $\\lim_{x \\rightarrow \\infty}F(x) = 1$, and $\\lim_{x \\rightarrow -\\infty}F(x) = 0$.\n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "1\\. Suppose that for $n \\in \\mathbb N$, $x_n \\uparrow \\infty$.\n",
    "\n",
    "Then with $A_n = \\{X \\leq x_n\\} \\equiv \\{\\omega : X(\\omega) \\leq x\\}$, it is clear that $A_n \\uparrow \\Omega$ as $n \\rightarrow \\infty$. This follows because the codomain for $X$, $(\\mathbb R, \\mathcal R)$, is upper-bounded by $\\infty$. \n",
    "\n",
    "Then:\n",
    "```{math}\n",
    "    F(x_n) &\\equiv \\mathbb P(X \\leq x_n) \\equiv \\mathbb P(A_n) \\equiv \\mathbb P(\\{\\omega : X(\\omega) \\leq x_n\\}) \\\\\n",
    "    &\\uparrow \\mathbb P(\\Omega) = 1,\n",
    "```\n",
    "where the convergence from below is by {prf:ref}`uv:mt:prob_spaces:meas:convbelow`.\n",
    "\n",
    "2\\. Suppose that for $n \\in \\mathbb N$, $x_n \\downarrow -\\infty$.\n",
    "\n",
    "Then with $A_n = \\{X \\leq x_n\\}$, it is clear that $A_n \\downarrow \\varnothing$ as $n \\rightarrow \\infty$. This is because the codomain for $X$ is lower-bounded by $-\\infty$.\n",
    "\n",
    "Then:\n",
    "```{math}\n",
    "    F(x_n) \\equiv \\mathbb P(X \\leq x_n) = \\mathbb P(A_n) \\downarrow \\mathbb P(\\varnothing) = 0,\n",
    "```\n",
    "where the convergence from above is by {prf:ref}`uv:mt:prob_spaces:meas:convabove`.\n",
    "````\n",
    "\n",
    "Another property we will make substantial use of with respect to distribution functions is that they are right continuous, and not (necessarily) left-continuous:\n",
    "\n",
    "````{prf:property} Right-continuity of distribution function\n",
    "Suppose the probability space $(\\Omega, \\mathcal F, \\mathbb P)$, and that $X \\in m\\mathcal F$ is a random variable with distribution function $F$. $\\lim_{y \\downarrow x}F(y) = F(x)$. \n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "Suppose that $(x_n)_{n \\in \\mathbb N} \\subset \\mathbb R$ is a countable sequence where $x_n \\downarrow x$, and $x \\not \\in (x_n)_{n \\in \\mathbb N}$. Such a sequence exists, by the completeness of the reals.\n",
    "\n",
    "Note that for any such $x_n$, that $A_n \\triangleq \\{\\omega : X(\\omega) \\leq x_n\\} \\supset \\{\\omega : X(\\omega) \\leq x\\}$, since $x_n > x$. \n",
    "\n",
    "Further, note that $\\bigcap_{n \\in \\mathbb n} A_n = \\{X \\leq x\\} \\equiv \\{\\omega : X(\\omega) \\leq x\\}$, because for any $\\epsilon$, $\\exists N$ s.t. for all $m > N$, $x_m - x < \\epsilon$, by definition of $x_n \\downarrow x$ as $n \\rightarrow \\infty$. \n",
    "\n",
    "Then:\n",
    "```{math}\n",
    "    F(x_n) &= \\mathbb P(A_n) \\\\\n",
    "    &\\downarrow \\mathbb P(X \\leq x) \\equiv \\mathbb P(\\{\\omega : X(\\omega) \\leq x\\}) = F(x).\n",
    "```\n",
    "where the convergence from above is by {prf:ref}`uv:mt:prob_spaces:meas:convabove`.\n",
    "````\n",
    "\n",
    "The key fine point here for the (potential) lack of left-continuity is that, as we see here, the right-hand side of the following equality is $\\mathbb P(X < x)$, and *not* $F(x) = \\mathbb P(X \\leq x)$:\n",
    "\n",
    "````{prf:property} Distribution functions (not necessarily) left-continuous\n",
    "Suppose the probability space $(\\Omega, \\mathcal F, \\mathbb P)$, and that $X \\in m\\mathcal F$ is a random variable with distribution function $F$. Then $F(x^-) \\triangleq \\lim_{y \\uparrow x}F(y) = \\mathbb P(X < x)$. \n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "Suppose that $(x_n)_{n \\in \\mathbb N}\\subset \\mathbb R$ is a countable sequence where $x_n \\uparrow x$, and $x \\not \\in (x_n)_{n \\in \\mathbb N}$. Such a sequence exists, by the completeness of the reals. \n",
    "\n",
    "\n",
    "Note that for any such $x_n$, that $A_n \\triangleq \\{X \\leq x_n\\} \\equiv \\{\\omega : X(\\omega) \\leq x_n\\} \\subset \\{\\omega : X(\\omega) \\leq x\\} \\equiv \\{X \\leq x\\}$, since $x_n > x$. \n",
    "\n",
    "Further, note that $\\bigcup_{n \\in \\mathbb N}A_n = \\{\\omega : X(\\omega) < x\\}$. This follows because $x \\not \\in (x_n)_{n \\in \\mathbb N}$ by construction, and by applying the definition of the countable set union. This holds for any countable sequence as-described.\n",
    "\n",
    "Then:\n",
    "```{math}\n",
    "    F(x_n) &= \\mathbb P(A_n) \\\\\n",
    "    &\\uparrow \\mathbb P(X < x) \\equiv \\mathbb P(\\{\\omega : X(\\omega) < x\\}).\n",
    "```\n",
    "where the convergence from below is by {prf:ref}`uv:mt:prob_spaces:meas:convbelow`.\n",
    "````\n",
    "\n",
    "Finally, the probability at any particular point can be taken to be the difference in the distribution function at that value, minus the limit point we defined above:\n",
    "\n",
    "````{prf:property} Probability at a point\n",
    "Suppose the probability space $(\\Omega, \\mathcal F, \\mathbb P)$, and that $X \\in m\\mathcal F$ is a random variable with distribution function $F$. Then $\\mathbb P(X = x) = F(x) - F(x^-)$.\n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "Note that $\\{\\omega : X(\\omega) = x\\} = \\{\\omega : X(\\omega) \\leq x\\} \\setminus \\{\\omega : X(\\omega) < x\\}$.\n",
    "\n",
    "Further, note that $\\{\\omega : X(\\omega) \\leq x\\} \\supseteq \\{\\omega : X(\\omega) < x\\}$. Then by {prf:ref}`uv:mt:prob_spaces:meas:measdiff`, since $\\mathbb P$ is a measure:\n",
    "```{math}\n",
    "    \\mathbb P(X = x) &= \\mathbb P\\left(\\{X \\leq x\\} \\setminus \\{X < x\\}\\right) \\\\\n",
    "    &= \\mathbb P(X \\leq x) - \\mathbb P(X < x) \\\\\n",
    "    &\\equiv F(x) - F(x^-).\n",
    "```\n",
    "````\n",
    "\n",
    "## The Skorokhod Representation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
