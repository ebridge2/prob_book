{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "developmental-convention",
   "metadata": {},
   "source": [
    "(mt:int:props)=\n",
    "# Properties of Integration\n",
    "\n",
    "That last section was pretty neat stuff, eh? \n",
    "\n",
    "While this might seem like all we did was introduced a bunch of cumbersome notation to \"reinvent the wheel\" and give you back your Riemann integral from calculus, it turns out this is a lot more powerful than that stuff. In particular, you'll notice that we were *extremely* cautious every step of the way from the preceding chapters all the way to now regarding which assumptions different conditions hold under. These might seem like \"mindless details\" that you'd rather go without, but the brilliance of probability theory *is* the details. \n",
    "\n",
    "These properties that we are constructing, from the ground up, have been explicit about *every assumption* made along the way. As we build more and more results, we're going to keep that trend up, and all these assumptions and conditions are going to start making sense as you begin to see that extremely weak conditions might add up to a result that is beautiful. As you'll see in the next section, the concept of *expected value* in probability theory is *understood* as a special case of integration with respect to a *probability measure*, so while we're going to unfortunately burden you with some more properties of integrals, it will start to tie back to probability theory more directly next. \n",
    "\n",
    "## Norms and Convexity\n",
    "\n",
    "In this section, we'll learn some details about two concepts that we will later see are acutely related: norms and convex functions. When we attempt to classify random variables in the next chapter, we'll use these two concepts to do so.\n",
    "\n",
    "### Convex Functions\n",
    "\n",
    "We'll start off with a definition you've probably seen in some form before:\n",
    "````{prf:definition} Convex Function\n",
    ":label: mt:int:props:convex:defn\n",
    "A function $\\varphi : \\mathcal X \\rightarrow \\mathbb R$ defined on a convex subset $\\mathcal X \\subseteq \\mathbb R$ is convex if for all $\\lambda \\in (0, 1)$ and for all $x_1, x_2 \\in \\mathcal X$:\n",
    "```{math}\n",
    "    \\lambda\\varphi(x_1) + (1 - \\lambda)\\varphi(x_2) \\geq \\varphi\\left(\\lambda x_1 + (1 - \\lambda)x_2\\right).\n",
    "```\n",
    "````\n",
    "Let's think about what this means, intuitively. First: what the heck is a **convex subset** $\\mathcal X$? All that this means is, for all $x_1, x_2 \\in \\mathcal X$, that any possible *convex combination* of these elements $\\lambda x_1 + (1 - \\lambda)x_2$ is also $\\in \\mathcal X$. This holds for all $\\lambda \\in (0, 1)$. For instance, if we are dealing with real numbers, $\\mathcal X$ could just be an interval.\n",
    "\n",
    "The idea here is that in this case, the point $z = \\lambda x_1 + (1 - \\lambda)x_2$ is some point in *between* $x_1$ and $x_2$. This is ensured by the fact that $\\lambda$ is between $0$ and $1$. Now, let's think about the left side of an equation. What happens as $t$ changes? Graphically, it turns out that it looks something like this:\n",
    "\n",
    "```{figure} ./Images/convex.png\n",
    "---\n",
    "width: 700px\n",
    "name: mt:int:props:convexfig\n",
    "---\n",
    "**(A)** The red line represents the line $\\lambda \\varphi(x_1) + (1 - \\lambda)\\varphi(x_2)$ for some value $\\lambda \\in (0, 1)$. For a convex function, for any two points $x_1$ and $x_2$, this line will be *entirely* above the actual function, $\\varphi(x)$. **(B)** A non-convex function $\\psi$. Notice that we can choose points $x_1$ and $x_2$ where the red line is not always above the function.\n",
    "```\n",
    "\n",
    "An important consequence that we will use throughout this course is a relatively simple real analysis result:\n",
    "\n",
    "````{prf:lemma} Convex functions and second derivatives\n",
    ":label: mt:int:props:convex:second_deriv\n",
    "A function $\\varphi \\in C^2 : \\mathcal X \\rightarrow \\mathbb R$ defined on an interval $\\mathcal X$ is convex on $\\mathcal X$ if and only if for all $x \\in \\mathcal X$, $\\varphi''(x) \\geq 0$.\n",
    "````\n",
    "\n",
    "What this asserts is that if the function $\\varphi$ is further twice differentiable and the function is defined on an interval (which is a convex subset), we have a second way to assert convexity, which is (often) much easier to work with: simply check its second derivative. Visually, this solidifies an intuitive notion of convexity demonstrated by {numref}`mt:int:props:convexfig`(A): a convex function will be curved *upwards*. \n",
    "\n",
    "Now, we're going to talk about some nuancy points that are consequences of the definition of convex functions. In my opinion, the proofs/intuition of these results go somewhat beyond an introductory real analysis course, so you shouldn't worry if it doesn't immediately make sense to you:\n",
    "\n",
    "````{prf:lemma} Subderivatives of convex functions\n",
    ":label: mt:int:props:convex:subderiv\n",
    "Suppose that the function $\\varphi : \\mathcal X \\rightarrow \\mathbb R$ defined on a convex open subset $\\mathcal X \\subseteq \\mathbb R$ is convex. The the *subderivative* at a point $x_0 \\in \\mathcal X$ is a real number $c$ s.t. for all $x \\in \\mathcal X$:\n",
    "```{math}\n",
    "    c  \\leq \\frac{\\varphi(x) - \\varphi(x_0)}{x - x_0}.\n",
    "```\n",
    "````\n",
    "That $\\mathcal X$ is *open* suggests that if $x \\in \\mathcal X$, that the neighborhood $\\{x + h\\}_{0 < h < \\epsilon} \\subseteq \\mathcal X$ for some $\\epsilon > 0$. As it turns out, for a convex function $\\varphi$, we can take this even further, and can say that:\n",
    "```{math}\n",
    "    a_l &= \\lim_{h \\downarrow 0}\\frac{\\varphi(x) - \\varphi(x - h)}{h} \\\\\n",
    "    a_u &= \\lim_{h \\downarrow 0}\\frac{\\varphi(x + h) - \\varphi(x)}{h}\n",
    "```\n",
    "are both finite, and $[a_l, a_u]$ is called the **subdifferential** (it is a set of all of the subdifferentials). When the function $f$ is continuously differentiable on the entire domain $\\mathcal X$, this is fairly rudimentary what we are talking about here: $a_l$ and $a_u$ are the left and right derivatives for a point $x$ (and, in the case of continuous functions, these are *equal*). The nuance here can be shown with something that is convex but *not* continuously differentiable, like the absolute value:\n",
    "\n",
    "```{figure} ./Images/subderiv.png\n",
    "---\n",
    "width: 400px\n",
    "name: mt:int:props:subderiv\n",
    "---\n",
    "In this case, we can see two sub-tangent lines at the point $x = 0$, which are lines which intersect with $f(x) = |x|$ at $x = 0$ but whose slopes are in the interval formed by the left and right derivatives, $-1$ and $1$ respectively. The sub-derivatives exist since $f(x) = |x|$ is convex; if you are struggling with why it is convex, think about the lines we drew previously in {numref}`mt:int:props:convexfig`.\n",
    "```\n",
    "\n",
    "Now we get to one of the fundamental results of integration:\n",
    "\n",
    "````{prf:theorem} Jensen's Inequality\n",
    ":label: mt:int:props:convex:jensen\n",
    "Suppose that:\n",
    "1. $(\\Omega, \\mathcal F, \\mathbb P)$ is a probability space,\n",
    "2. $\\mathcal X \\subseteq \\mathbb R$ is an interval,\n",
    "3. $f \\in m\\mathcal F : \\Omega \\rightarrow \\mathcal X$ is a measurable function, \n",
    "4. $\\varphi \\in m\\mathcal R: \\mathcal X \\rightarrow \\mathbb R$ is convex, and\n",
    "5. $f$ and $\\varphi(f) = \\varphi \\circ f$ are $\\mathbb P$-integrable.\n",
    "\n",
    "Then:\n",
    "```{math}\n",
    "    \\varphi\\left(\\int f \\,\\text d \\mathbb P\\right) \\leq \n",
    "    \\int \\varphi\\left(f\\right) \\,\\text d \\mathbb P.\n",
    "```\n",
    "````\n",
    "This result, it turns out, is pretty easy to prove if $f$ is *also* $C^2$, but that wouldn't quite be as general as we want it to be: this result can hold for *any* convex functions, not just the $C^2$ ones. In the proof below, we use the concept of the sub-derivative that we just intuited our way through, and then we'll recap why we had to use sub-derivatives at all once we're done:\n",
    "````{prf:proof}\n",
    "Let $c = \\int f \\,\\text d\\mathbb P$, which is finite since $f$ is $\\mathbb P$-integrable {prf:ref}`mt:int:basics:muint:int`.\n",
    "\n",
    "Let $\\ell(x) = a x + b$ be a linear function for $a, b, x \\in \\mathbb R$ s.t. $\\ell(c) = \\varphi(c)$, and $\\varphi(x) \\geq \\ell(x)$. Such a function $\\ell$ exists, since by the convexity of $\\varphi$, we can see that with:\n",
    "```{math}\n",
    "    a_l = \\lim_{h \\downarrow 0}\\frac{\\varphi(c) - \\varphi(c - h)}{h} \\leq \\lim_{h \\downarrow 0}\\frac{\\varphi(c + h) - \\varphi(c)}{h} = a_u,\n",
    "```\n",
    "Letting $a \\in [a_l, a_u]$ ($a$ is a *sub-derivative* of $\\varphi$) and $\\ell(x) = a(x - c) + \\varphi(c)$ gives the desired properties, as:\n",
    "```{math}\n",
    "    x \\neq c \\Rightarrow \\ell(x) &\\leq a_u(x - c) + \\varphi(c),\\,\\,\\,\\,\\text{defn. of a sub-derivative}, a \\leq a_u \\\\\n",
    "    x = c \\Rightarrow \\ell(c) &= \\varphi(c).\n",
    "```\n",
    "Note, then, that $\\varphi(x) \\geq \\ell(x)$ for any $x \\in \\mathbb R$, and consequently, $\\varphi \\circ f \\geq \\ell \\circ f$, so $\\varphi \\circ f \\overset{a.e.}{\\geq} \\ell \\circ f$. \n",
    "\n",
    "It is pretty that $\\ell \\circ f$ is a rescaling of an integrable function $f$ by $a$ and a sum with a constant term, $-ac + \\varphi(c)$. Particularly, here note that since we have a probability space, the measure of the entire space is finite, and the constant is integrable by {prf:ref}`mt:int:basics:constants`. Therefore, $\\ell \\circ f$ is integrable by {prf:ref}`mt:int:basics:muint:rescale` and {prf:ref}`mt:int:basics:muint:sum`.\n",
    "\n",
    "Then by {prf:ref}`mt:int:basics:int:cor:ineq`, since $\\varphi \\circ f$ is integrable by supposition:\n",
    "```{math}\n",
    "    \\int \\varphi\\circ f \\, \\text d\\mathbb P &\\geq \n",
    "    \\int \\ell \\circ f \\, \\text d\\mathbb P \\\\\n",
    "    &= \\int \\left(a f - c + \\varphi(c)\\right) \\, \\text d\\mathbb P \\\\\n",
    "    &= a\\left(\\int f\\,\\text d \\mathbb P - c\\right) + \\varphi(c) \\\\\n",
    "    &= \\ell\\left(\\int f\\,\\text d\\mathbb P\\right),\\,\\,\\,\\,\\ell(x) \\triangleq a(x - c) + \\varphi(c) \\\\\n",
    "    &= \\varphi\\left(\\int f \\, \\text d \\mathbb P\\right),\\,\\,\\,\\,\\ell(c) = \\varphi(c)\n",
    "```\n",
    "where by construction, $c = \\int f \\,\\text d \\mathbb P$.\n",
    "````\n",
    "So: why did we have to use sub-derivatives, and what did they let us do? Well, since $\\varphi$ is only convex, it is entirely possible that the derivative doesn't exist at a point we are interested in (think about if the absolute value had an inflection right at $x = \\int f \\,\\text d \\mathbb P$ instead of at $x = 0$, like in the figure we considered; e.g., $\\varphi(x) = \\left|x - \\int f \\,\\text d \\mathbb P\\right|$). So, what we did was, we constructed a *sub-tangent* line via a sub-derivative at this point, just to give us extra protection for the general case where we could have a non-existant derivative. \n",
    "\n",
    "### Norms\n",
    "\n",
    "Jensen's inequality will make properties about norms of random variables very easy to prove. What's a norm you might ask?\n",
    "\n",
    "````{prf:definition} Functional norm\n",
    ":label: mt:int:props:norm:defn\n",
    "Suppose that $(\\Omega, \\mathcal F, \\mu)$ is a measure space, and suppose that $p \\in [1, \\infty)$. The functional norm of a function $f \\in m\\mathcal F : \\Omega \\rightarrow \\mathbb R$ is:\n",
    "```{math}\n",
    "||f||_p \\triangleq \\left(\\int |f|^p \\,\\text d \\mu\\right)^{\\frac{1}{p}}\n",
    "```\n",
    "````\n",
    "We tend to classify functions as those that have finite functional norms:\n",
    "\n",
    "````{prf:definition} $\\mathbb L^p$ space\n",
    "Suppose that $(\\Omega, \\mathcal F, \\mu)$ is a measure space, and suppose that $p \\in [1, \\infty)$. Then the $\\mathbb L^p(\\mu)$ space is the set of measurable functions:\n",
    "```{math}\n",
    "    \\mathbb L^p(\\mu) \\triangleq \\left\\{f \\in m\\mathcal F : ||f||_p < \\infty\\right\\}\n",
    "```\n",
    "````\n",
    "\n",
    "We can use functional norms to obtain some more desirable properties of integration. Let's check out Hölder's inequality:\n",
    "\n",
    "````{prf:theorem} Hölder's inequality\n",
    ":label: mt:int:props:convex:holder\n",
    "Suppose that $(\\Omega, \\mathcal F, \\mu)$ is a measure space, that $f, g \\in m\\mathcal F$, and that $p, q \\in [1, \\infty)$ are s.t. $\\frac{1}{p} + \\frac{1}{q} = 1$. Then:\n",
    "```{math}\n",
    "    \\int |f \\cdot g| \\,\\text d \\mu \\leq ||f||_p ||g||_q.\n",
    "```\n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "If $||f||_p = 0$, then note that by definition, $\\mu\\left(\\{\\omega : f(\\omega) \\neq 0\\}\\right) = 0$ and so $f \\overset{a.e.}{=} 0$, and vice-versa for $||g||_q$. \n",
    "\n",
    "In this case, the product $f \\circ g \\overset{a.e.}{=} 0$, as $(f\\cdot g)(\\omega) \\equiv f(\\omega)g(\\omega) = 0$ as well, satisfying the inequality.\n",
    "\n",
    "Therefore, suppose that $||f||_p, ||g||_q > 0$. Further, WOLOG, assume that $||f||_p = ||g||_q = 1$. Note that this applies generally, as we could simply take $f'(\\omega) = \\frac{f(\\omega)}{||f||_p}$ and vice-versa for $g$, and we would obtain a result that is simply a scalar multiple of $||f||_p||g||_q$, since $|f(\\omega) g(\\omega)| = ||f||_p||g||_q|f'(\\omega)g'(\\omega)|$ since by definition, $||f||_p, ||g||_q > 0$. \n",
    "\n",
    "Note that for any $x, y \\geq 0$, that using basic properties of the $\\exp$ and $\\log$ functions:\n",
    "```{math}\n",
    "    xy &= \\exp(\\log(xy)) \\\\\n",
    "    &= \\exp(\\log x + \\log y) \\\\\n",
    "    &= \\exp\\left(\\frac{1}{p} p\\log x + \\frac{1}{q}q \\log y\\right) \\\\\n",
    "    &= \\exp\\left(\\frac{1}{p} \\log x^p + \\frac{1}{q} \\log y^q\\right)\n",
    "```\n",
    "Notice that $\\exp(x)$ is convex, since its second derivative is positive by {prf:ref}`mt:int:props:convex:second_deriv`. Then since $\\frac{1}{p} + \\frac{1}{q}$ is positive:\n",
    "```{math}\n",
    "    xy &\\leq \\frac{1}{p} \\exp(\\log x^p) + \\frac{1}{q} \\exp(\\log y^q) \\\\\n",
    "    &= \\frac{x^p}{p} + \\frac{y^q}{q}.\n",
    "```\n",
    "Taking $x = |f(\\omega)|$ and $y = |g(\\omega)|$, we see that:\n",
    "```{math}\n",
    "    |f(\\omega)||g(\\omega)| = |f(\\omega)g(\\omega)| \\leq \\frac{|f(\\omega)|^p}{p} + \\frac{|g(\\omega)|^q}{q},\n",
    "```\n",
    "which holds for all $\\omega \\in \\Omega$, so $|f \\cdot g| \\leq \\frac{|f|^p}{p} + \\frac{|g|^q}{q}$. Integrating:\n",
    "\n",
    "```{math}\n",
    "    \\int |f \\cdot g| \\,\\text d \\mu &\\leq \\int \\left(\\frac{|f|^p}{p} + \\frac{|g|^q}{q}\\right)\\,\\text d \\mu \\\\\n",
    "    &= \\frac{||f||_p}{p} + \\frac{||g||_q}{q} \\\\\n",
    "    &= \\frac{1}{p} + \\frac{1}{q},\\,\\,\\,\\,||f||_p = ||g||_q = 1\\text{ WOLOG} \\\\\n",
    "    &= 1,\\,\\,\\,\\,\\frac{1}{p} + \\frac{1}{q} \\text{ by supposition} \\\\\n",
    "    &= ||f||_p ||g||_q.\n",
    "```\n",
    "\n",
    "````\n",
    "\n",
    "## Convergence Results\n",
    "\n",
    "### Convergence Concepts\n",
    "\n",
    "Next, we get to the convergence theorems for integrals. To do this, we first need two quick definitions to get us started:\n",
    "\n",
    "````{prf:definition} Convergence Almost Everywhere\n",
    ":label: mt:int:props:conv:convae\n",
    "Suppose the measure space $(\\Omega, \\mathcal F, \\mu)$, and the measurable functions $f, f_n \\in m\\mathcal F$, for all $n \\in \\mathbb N$. We say that $f_n \\xrightarrow[n \\rightarrow \\infty]{a.e.} f$ if:\n",
    "```{math}\n",
    "    \\mu\\left(\\left\\{\\omega \\in \\Omega : \\lim_{n \\rightarrow \\infty}f_n(\\omega) \\neq f(\\omega)\\right\\}\\right) \\equiv \\mu(\\lim_{n \\rightarrow \\infty}f_n \\neq f) = 0.\n",
    "```\n",
    "````\n",
    "The idea here is that for all but a set of measure $0$, $f_n(\\omega) \\xrightarrow[n \\rightarrow \\infty]{} f(\\omega)$. Stated another way, we have pointwise convergence of $f_n$ to $f$ almost everywhere. \n",
    "\n",
    "\n",
    "We can also understand this definition using the concept of the $\\limsup$ of a set, in an $\\epsilon$ sort of way like you are used to in real analysis:\n",
    "\n",
    "````{prf:definition} Equivalent definition for convergence almost everywhere\n",
    "Suppose the measure space $(\\Omega, \\mathcal F, \\mu)$, and the measurable functions $f, f_n \\in m\\mathcal F$, for all $n \\in \\mathbb N$. We say that $f_n \\xrightarrow[n \\rightarrow \\infty]{a.e.} f$ if for every $\\epsilon > 0$:\n",
    "```{math}\n",
    "    \\mu\\left(\\limsup_{n \\rightarrow \\infty}\\left\\{\\omega \\in \\Omega : |X_n(\\omega) - X(\\omega)| > \\epsilon\\right\\}\\right) = 0.\n",
    "```\n",
    "````\n",
    "In this definition, the intuition is that we are focusing on a sequence of sets (indexed by $n$) which are the points $\\omega$ of the sample space $\\Omega$ which are *not* $\\epsilon$-close to $f(\\omega)$. These are the sets of the form:\n",
    "```{math}\n",
    "    \\left\\{\\omega \\in \\Omega : |f_n(\\omega) - f(\\omega)| > \\epsilon\\right\\}_{n \\in \\mathbb N}.\n",
    "```\n",
    "Remember that $\\limsup_{n \\rightarrow \\infty}$ of a sequence of sets can be more specifically be understood to be the $\\inf_{n \\rightarrow\\infty}\\sup_{m \\geq n}$, so we are concerned with the $\\inf$ of sets of the form:\n",
    "```{math}\n",
    "    F_n = \\sup_{m \\geq n}\\left\\{\\omega \\in \\Omega : |X_m(\\omega) - X(\\omega)| > \\epsilon\\right\\}\n",
    "```\n",
    "So, the interpretation of $F_n$ here is that it's the *largest possible* measurable set of the sample space where for every $m \\geq n$, $|f_m(\\omega) - f(\\omega)| > \\epsilon$ (which is the definition of $f_m(\\omega)$ *not* being $\\epsilon$-close to $f(\\omega)$ which is a condition for the limit to be $f(\\omega)$). The nuance here is that we use a supremum, which is because it's not immediately clear that the largest possible set that fulfills this criterion will *necessarily* be measurable (but, as-per {prf:ref}`mt:intro:rvs:elem:ext:sup`, we know for sure that the supremum *is* measurable). \n",
    "\n",
    "By construction, since $n$ is increasing, notice that $\\{F_n\\}_{n \\in \\mathbb N}$ are monotone *non-increasing*: $F_n \\supseteq F_{n + 1}$, for all $n \\in \\mathbb N$. Intuitively, since it is bounded (from below by $\\varnothing$) and monotone non-increasing, the infimum of these sequences of sets exist (by {prf:ref}`mt:intro:set:sig:monotone_sets:lim`). We know for sure that the resulting set is further measurable by just checking {prf:ref}`mt:intro:rvs:elem:ext:inf`.\n",
    "\n",
    "Next, we get to a practically distinct definition, which *almost* looks the same. This concept is called convergence in measure:\n",
    "\n",
    "````{prf:definition} Convergence in measure\n",
    ":label: mt:int:props:conv:convmeas\n",
    "Suppose the measure space $(\\Omega, \\mathcal F, \\mu)$, and the measurable functions $f, f_n \\in m\\mathcal F$, for all $n \\in \\mathbb N$. We say that $f_n \\xrightarrow[n \\rightarrow \\infty]{} f$ in measure if for any $\\epsilon > 0$, then:\n",
    "```{math}\n",
    "    \\mu\\left(\\left\\{\\omega \\in \\Omega : |f_n(\\omega) - f(\\omega)| > \\epsilon\\right\\}\\right) \\equiv \\mu(|f_n - f| > \\epsilon) \\xrightarrow[n \\rightarrow \\infty]{} 0.\n",
    "```\n",
    "````\n",
    "While these definitions almost look the same, the practical distinction is that the limit, this time, is *outside* of the measure statement. The idea here is that, as $n$ grows, the measure of the set of points $\\omega$ where $f_n(\\omega)$ is not $\\epsilon$-close to $f(\\omega)$ is converging to zero. This contrasts from the fact that in the preceding statement, the measure of the set of points $\\omega$ where $f_n(\\omega)$ is not $\\epsilon$-close to $f(\\omega)$ as $n \\rightarrow \\infty$ *is* zero. Intuitively, convergence almost everywhere, in fact, *implies* convergence in measure (with the slight note that the entire space $\\Omega$ must have finite measure). Let's formalize this up a bit:\n",
    "\n",
    "````{prf:lemma} Convergence almost everywhere implies convergence in measure\n",
    ":label: mt:int:props:conv:convae_implies_convinmeas\n",
    "Suppose the measure space $(\\Omega, \\mathcal F, \\mu)$, and the measurable functions $f, f_n \\in m\\mathcal F$, for all $n \\in \\mathbb N$, where $\\{f_n\\}_{n \\in \\mathbb N} \\subset m\\mathcal F$. If $f_n \\xrightarrow[n \\rightarrow \\infty]{a.e.} f$ and $\\mu(\\omega) < \\infty$, then $f_n \\xrightarrow[n \\rightarrow \\infty]{} f$ in measure.\n",
    "````\n",
    "````{prf:proof}\n",
    "Suppose that $f_n  \\xrightarrow[n \\rightarrow \\infty]{a.e.} f$. \n",
    "\n",
    "Let $\\Omega_1 \\triangleq \\{\\omega \\in \\Omega : \\lim_{n \\rightarrow \\infty}f_n(\\omega) = f(\\omega)\\}$, and $\\Omega_1^c = \\Omega \\setminus \\Omega_1$. By construction, note that $\\mu(\\Omega_1^c) = 0$.\n",
    "\n",
    "By definition of $\\xrightarrow[n \\rightarrow \\infty]{a.e.}$, then $\\mu(\\Omega_1^c) = 0$. Fix $\\epsilon > 0$, and consider the sequence of sets:\n",
    "```{math}\n",
    "F_n \\triangleq \\bigcup_{m \\geq n}\\left\\{|f_n - f| > \\epsilon\\right\\}.\n",
    "```\n",
    "By construction, note that $F_n \\supseteq F_{n + 1}$, where $F_n \\downarrow F_\\infty = \\bigcap_{n \\in \\mathbb N}F_n$.\n",
    "\n",
    "Further, note that by design, for any $\\omega \\in \\Omega_1$, that $\\lim_{n \\rightarrow \\infty}f_n(\\omega) = f(\\omega)$. Then for any $\\epsilon > 0$, there exists $N_\\epsilon$ s.t. for all $n \\geq N_\\epsilon$, $|f_n(\\omega) - f(\\omega)| \\leq \\epsilon$, by definition of a limit.\n",
    "\n",
    "Then for all $n > N_\\epsilon$, $\\omega \\not \\in F_n$, and consequently $\\omega \\not \\in F_\\infty$.\n",
    "\n",
    "Then $F_\\infty \\cap \\Omega_1 = \\varnothing$; that is, $F_\\infty \\subseteq \\Omega_1^c$. \n",
    "\n",
    "Then by definition of a measure, $\\mu(F_\\infty) \\leq \\mu(\\Omega_1^c) = 0$ by the way we constructed $\\mu(\\Omega_1)^c$. Further, since measures are lower-bounded by $0$, this implies that $\\mu(F_\\infty) = 0$. \n",
    "\n",
    "Then since $F_n \\downarrow F_\\infty$:\n",
    "```{math}\n",
    "    \\mu(|X_n - X| > \\epsilon) &\\leq \\mu(F_n),\\,\\,\\,\\,\\{|X_n - X| > \\epsilon\\} \\subseteq F_n \\\\\n",
    "    &\\downarrow \\mathbb P(A_\\infty) = 0\\text{ as $n \\rightarrow \\infty$},\n",
    "```\n",
    "by the convergence from above property of measures, {prf:ref}`mt:intro:prob_spaces:meas:convabove`.\n",
    "````\n",
    "\n",
    "We aren't *quite* ready to handle the result that $f_n \\xrightarrow[n \\rightarrow \\infty]{} f$ is measure does *not* imply that $f_n \\xrightarrow[n \\rightarrow \\infty]{a.e.} f$, so we'll rotate back to this a little later in the course.\n",
    "\n",
    "Let's see what these two concepts will allow us to do.\n",
    "\n",
    "### Convergence Theorems\n",
    "\n",
    "````{prf:theorem} Bounded Convergence\n",
    ":label: mt:int:props:conv:bct\n",
    "Suppose the measure space $(\\Omega, \\mathcal F, \\mu)$, where:\n",
    "1. $F\\in \\mathcal F$ is a $\\mu$-finite set, where $\\mu(F) < \\infty$,\n",
    "2. $\\{f_n\\}_{n \\in \\mathbb N} \\subseteq m\\mathcal F$ is a sequence of measurable functions which vanish on $F^c$; that is, $\\omega \\in F^c \\Rightarrow f_n(\\omega) = 0$,\n",
    "3. There exists $M$ s.t. $|f_n(\\omega)| \\leq M$ ($f_n$ are each bounded), and\n",
    "4. $f_n \\xrightarrow[n \\rightarrow \\infty]{} f$ in measure.\n",
    "\n",
    "Then:\n",
    "```{math}\n",
    "    \\int_F f\\,\\text d \\mu = \\lim_{n \\rightarrow \\infty}\\int_F f_n\\,\\text d \\mu.\n",
    "```\n",
    "````\n",
    "The idea here is that we are conceptually moving the limit *across* the integral: the left hand side can be thought of as the integral of $\\lim_{n \\rightarrow \\infty}f_n$ on sets that are progressively encompassing more and more of the sample space $\\Omega$. \n",
    "\n",
    "````{prf:proof}\n",
    "Suppose that $\\epsilon > 0$, and define $G_n \\triangleq \\{\\omega \\in F : |f_n(\\omega) - f(\\omega)| \\leq \\epsilon\\}$, and $B_n \\triangleq F \\setminus G_n = \\{\\omega \\in F : |f_n(\\omega) - f(\\omega)| > \\epsilon\\}$. Intuitively, $G_n$ are the points of $F$ for a particular $n$ where $f_n(\\omega)$ is $\\epsilon$-close to $f(\\omega)$, and $B_n$ are the points where $f_n(\\omega)$ is not. \n",
    "\n",
    "Then by {prf:ref}`mt:int:basics:bounded_int`:\n",
    "```{math}\n",
    "    \\left|\\int_F f \\,\\text d \\mu - \\int_F f_n\\,\\text d \\mu \\right| &= \\left|\\int_F (f - f_n)\\,\\text d \\mu\\right| \\\\\n",
    "    &\\leq \\int_F |f - f_n|\\,\\text d \\mu,\\,\\,\\,\\,\\text{Jensen's inequality, as }|\\cdot|\\text{ is convex} \\\\\n",
    "    &= \\int_{G_n}|f - f_n| \\,\\text d\\mu + \\int_{B_n}|f - f_n| \\,\\text d\\mu,\\,\\,\\,\\,G_n \\sqcup B_n = F \\\\\n",
    "    &\\leq \\epsilon \\mu(F) + 2M\\mu(B_n),\n",
    "```\n",
    "For the left-hand expression, we used that for $\\omega \\in G_n$, $|f_n(\\omega) - f(\\omega)| \\leq \\epsilon$ by construction. For the right hand side, we used that $|f_n| \\leq M \\Rightarrow |f| \\leq M$ (bounded functions can only converge to a bounded function), and consequently we applied the triangle inequality, $|f - f_n| \\leq |f| + |f_n| \\leq 2M$. \n",
    "\n",
    "Continuing:\n",
    "```{math}\n",
    "    \\left|\\int_F f \\,\\text d \\mu - \\int_F f_n\\,\\text d \\mu\\right| \\xrightarrow[n \\rightarrow \\infty]{} \\epsilon \\mu(E),\n",
    "```\n",
    "since $\\mu(B_n) \\xrightarrow[n \\rightarrow \\infty]{} 0$ by definition of $f_n \\rightarrow f$ in measure. Noting that $0 \\leq \\mu(F) < \\infty$ by supposition, and that $\\epsilon$ was arbitrary, gives the desired result.\n",
    "````\n",
    "\n",
    "So, intuitively, as the functions $f_n$ get closer to $f$ *in measure* (the sets on which they disagree have measure converging to $0$), somewhat intuitively, the integrals converge, too. The key here is that the *bounded* convergence theorem applies for *bounded* functions. We have a somewhat equivalent, albeit practically much more applicable, result for non-negative functions:\n",
    "\n",
    "````{prf:lemma} Fatou\n",
    ":label: mt:int:props:conv:fatou\n",
    "Suppose the measure space $(\\Omega, \\mathcal F, \\mu)$, where $\\{f_n\\}_{n \\in \\mathbb N} \\subseteq m\\mathcal F$ is a sequence of non-negative functions; e.g., $f_n \\geq 0$. Then:\n",
    "```{math}\n",
    "    \\liminf_{n \\rightarrow \\infty} \\int f_n \\,\\text d \\mu \\geq \\int \\liminf_{n \\rightarrow \\infty} f_n \\,\\text d \\mu.\n",
    "```\n",
    "````\n",
    "\n",
    "````{prf:proof}\n",
    "Define $g_n$ to be the function where $g_n(\\omega) \\triangleq \\inf_{m \\geq n}f_n(\\omega)$. It follows that for all $n \\in \\mathbb N$, $f_n(\\omega) \\geq g_n(\\omega)$, since $g_n(\\omega)$ is the infimum of a set which contains $f_n(\\omega)$ by construction.\n",
    "\n",
    "Note that as $n \\rightarrow \\infty$, that $g_n(\\omega) \\uparrow g(\\omega)$ converges below to some value $g(\\omega)$ (possibly infinite), which follows because $g_{n + 1}(\\omega) \\geq g_n(\\omega)$, since $\\{f_m(\\omega) : m \\geq n+1\\} \\subseteq \\{f_m(\\omega) : m \\geq n\\}$ ($\\{g_n(\\omega)\\}_n$ is monotonically increasing in $n$).\n",
    "\n",
    "Then:\n",
    "```{math}\n",
    "    g_n(\\omega) \\uparrow g(\\omega) = \\sup_{n \\rightarrow \\infty}g_n(\\omega) = \\liminf_{n \\rightarrow \\infty} f_n(\\omega).\n",
    "```\n",
    "Since $\\int f_n\\,\\text d \\mu \\geq \\int g_n\\,\\text d \\mu$ by {prf:ref}`mt:int:basics:int:cor:ineq`, it is sufficient to show that:\n",
    "```{math}\n",
    "    \\liminf_{n \\rightarrow \\infty}\\int g_n\\,\\text d \\mu \\geq \\inf g \\,\\text d\\mu.\n",
    "```\n",
    "Let $\\{F_m\\} \\subseteq \\mathcal F$ be a sequence of sets which finite measure, where $F_m \\uparrow \\Omega$ as $m \\rightarrow \\infty$. Since $g_n \\geq 0$, then for fixed $m$:\n",
    "```{math}\n",
    "    (g_n(\\omega) \\wedge m)\\mathbb 1_{\\{F_m\\}}(\\omega) \\xrightarrow[n \\rightarrow \\infty]{} (g(\\omega) \\wedge m) \\mathbb 1_{\\{F_m\\}}(\\omega).\n",
    "```\n",
    "Then:\n",
    "```{math}\n",
    "    \\liminf_{n \\rightarrow \\infty}\\int g_n\\,\\text d\\mu \\geq \\int (g_n \\wedge m)\\mathbb 1_{\\{F_m\\}}\\,\\text d \\mu,\\,\\,\\,\\,0 \\leq g_n \\wedge m \\leq g_n \\\\\n",
    "    &= \\int_{F_m} (g_n \\wedge m)\\,\\text d \\mu \\\\\n",
    "    &\\xrightarrow[n \\rightarrow \\infty]{} \\int_{F_m}(g \\wedge m)\\,\\text d \\mu,\n",
    "```\n",
    "Note that both sides are at most upper-bounded by $m$, so {prf:ref}`mt:int:props:conv:bct` applies in the bottom line.\n",
    "\n",
    "Taking the sup over $m$:\n",
    "```{math}\n",
    "    \\liminf_{n \\rightarrow \\infty}\\int g_n\\,\\text d \\mu &= \\sup_m \\liminf_{n \\rightarrow \\infty}\\int g_n\\,\\text d \\mu \\\\\n",
    "    &\\xrightarrow[n \\rightarrow \\infty]{} \\sup_m \\int_{F_m}(g \\wedge m)\\,\\text d \\mu \\\\\n",
    "    &= \\int g\\,\\text d \\mu,\n",
    "```\n",
    "Notice that by definition of convergence from below, that by {prf:ref}`mt:int:basics:nn:int_compute` applies in the bottom line, and we are finished.\n",
    "````\n",
    "This is clearly much more general than the Bounded Convergence Theorem: the only restriction we have here is that we have a sequence of non-negative functions; we don't need a sequence of functions which is bounded and converging in measure.\n",
    "\n",
    "When the functions are converging below, we can further clarify the nature of the convergence with a slight extension of Fatou's Lemma: the integrals will also converge from below. In other words, functions converging \"monotonely\" have \"monotonely\" converging integrals:\n",
    "\n",
    "````{prf:theorem} Monotone Convergence (MCT)\n",
    ":label: mt:int:props:conv:mct\n",
    "Suppose the measure space $(\\Omega, \\mathcal F, \\mu)$, where $\\{f_n\\}_{n \\in \\mathbb N} \\subseteq m\\mathcal F$ is a sequence of non-negative functions; e.g., $f_n \\geq 0$, where $f_n \\uparrow f$ $\\mu$-a.e. ($f_n$ is monotone increasing to $f$). Then:\n",
    "```{math}\n",
    "    \\int f_n\\,\\text d \\mu \\uparrow \\int f\\,\\text d \\mu,\n",
    "```\n",
    "as $n \\rightarrow \\infty$.\n",
    "````\n",
    "As you notice, this theorem statement looks a lot like the statement from Fatou's Lemma {prf:ref}`mt:int:props:conv:fatou`, and in fact, we'll use some of the intuition from Fatou's Lemma to make this proof rigorous:\n",
    "````{prf:proof}\n",
    "By Fatou's Lemma {prf:ref}`mt:int:props:conv:fatou`, $f_n \\geq 0$ implies that:\n",
    "```{math}\n",
    "    \\liminf_{n \\rightarrow \\infty} \\int f_n\\,\\text d \\mu &\\geq \\int \\liminf_{n \\rightarrow \\infty}f_n\\,\\text d \\mu \\\\\n",
    "    &= \\int f \\,\\text d \\mu,\n",
    "```\n",
    "since $f_n \\uparrow f$ as $n \\rightarrow \\infty$ by supposition.\n",
    "\n",
    "Conversely, as $f_n \\overset{a.e.}{\\leq} f$ for all $n \\in \\mathbb n$, we see that by {prf:ref}`mt:int:basics:int:cor:ineq`:\n",
    "```{math}\n",
    "    \\limsup_{n \\rightarrow \\infty}\\int f_n\\,\\text d \\mu \\leq \\int f \\,\\text d \\mu.\n",
    "```\n",
    "Together, this gives that:\n",
    "```{math}\n",
    "    \\lim_{n \\rightarrow \\infty}\\int f_n\\,\\text d \\mu = \\int f \\,\\text d \\mu,\n",
    "```\n",
    "Which is because we have that $\\limsup_{n \\rightarrow \\infty}\\int f_n\\,\\text d \\mu \\leq \\int f \\,\\text d \\mu \\leq \\limsup_{n \\rightarrow \\infty}\\int f_n\\,\\text d \\mu$, which only holds in the case of equality because the $\\limsup$ is greater than or equal to the $\\liminf$ of the same sequence.\n",
    "\n",
    "Finally, note that $0 \\leq f_n \\uparrow f$ $\\mu$-a.e. as $n\\rightarrow \\infty$, which implies that $0 \\overset{a.e.}{\\leq} f_n \\overset{a.e.}{\\leq} f_{n + 1}$, so by {prf:ref}`mt:int:basics:int:cor:ineq`, we have that:\n",
    "```{math}\n",
    "\\int f_n\\,\\text d \\mu \\leq \\int f_{n + 1}\\,\\text d \\mu\n",
    "```\n",
    "for all $n \\in \\mathbb N$.\n",
    "\n",
    "Then $\\{\\int f_n\\,\\text d \\mu\\}_n$ is a monotone non-decreasing sequence, and its limit is $\\int f \\,\\text d \\mu$, as desired.\n",
    "````\n",
    "\n",
    "Next, we'll see another application of Fatou's Lemma, which is called the Dominated Convergence Theorem. Basically, what this theorem asserts is that if a sequence of measurable functions $f_n$ are converging almost surely to another function $f$, and can be *dominated* by a $\\mu$-integrable function, then the integrals converge, too:\n",
    "\n",
    "````{prf:theorem} Dominated Convergence (DCT)\n",
    ":label: mt:int:props:conv:dct\n",
    "Suppose the measure space $(\\Omega, \\mathcal F, \\mu)$, where:\n",
    "1. $\\{f_n\\}_{n \\in \\mathbb N} \\subseteq m\\mathcal F$, \n",
    "2. $f \\in m\\mathcal F$ is a function where $f_n \\xrightarrow[n \\rightarrow \\infty]{a.e.} f$, and\n",
    "3. $g$ is $\\mu$-integrable,\n",
    "4. $|f_n| \\leq g$ for all $n \\in \\mathbb N$.\n",
    "\n",
    "Then:\n",
    "```{math}\n",
    "    \\int f_n\\,\\text d \\mu \\xrightarrow[n \\rightarrow \\infty]{} \\int f \\,\\text d \\mu.\n",
    "```\n",
    "````\n",
    "The idea here is that $g$ is dominating the $f_n$ by condition 4. Consequently, since $f_n$ are converging a.e. to $f$, then $g$ dominates $f$ too, which suggests that $f$ (and further, the entire sequence $\\{f_n\\}$) are $\\mu$-integrable. Intuitively, this is because the integral of any function which is dominated by $g$ can be at most $\\int |g|\\,\\text d \\mu$.\n",
    "\n",
    "````{prf:proof}\n",
    "Note that since $|f_n| \\leq g$, then $-f_n \\leq g \\Rightarrow f_n + g \\geq 0$, and consequently, Fatou's lemma applies. Then:\n",
    "```{math}\n",
    "    \\liminf_{n \\rightarrow \\infty}\\int (f_n + g) \\,\\text d \\mu &\\geq \\int \\liminf_{n \\rightarrow \\infty}\\left(f_n + g\\right)\\,\\text d \\mu,\\,\\,\\,\\,\\text{Fatou} \\\\\n",
    "    &= \\int (f + g) \\,\\text d \\mu,\\,\\,\\,\\,f_n \\xrightarrow[]{a.e.} f.\n",
    "```\n",
    "By subtracting $\\int g \\,\\text d \\mu$ from both sides:\n",
    "```{math}\n",
    "    -\\int g \\,\\text d \\mu \\Rightarrow \\liminf_{n \\rightarrow \\infty}\\int f_n \\,\\text d \\mu \\geq \\int f \\,\\text d \\mu,\n",
    "```\n",
    "which follows by {prf:ref}`mt:int:basics:muint:sum`. \n",
    "\n",
    "Applying the same approach to $-f_n$, we obtain that $\\liminf_{n \\rightarrow \\infty}-\\int f_n\\,\\text d \\mu \\geq -\\int f\\,\\text d\\mu$, which implie sthat $\\limsup_{n \\rightarrow \\infty}f_n\\,\\text d \\mu \\leq \\int f\\,\\text d \\mu$.\n",
    "\n",
    "Since $\\liminf_{n \\rightarrow \\infty}\\int f_n \\,\\text d \\mu \\geq \\int f \\,\\text d \\mu \\geq  \\limsup_{n \\rightarrow \\infty}\\int f_n \\,\\text d \\mu$, equality must hold, since the $\\limsup$ is greater than or equal to the $\\liminf$ of the same sequence.\n",
    "````\n",
    "\n",
    "## Measure Restriction\n",
    "\n",
    "The final building block we will need in integration is the concept of measure restrictions. As its name somewhat suggests, a *measure restriction* basically lets us take an existing measure space $(\\Omega, \\mathcal F, \\mu)$, and define a *new* measure space from only a subset $F \\subseteq \\Omega$ that *agrees with* $\\mu$ on a new $\\sigma$-algebra that is, intuitively, induced by $F$. In some sense, this is kind of the opposite of the extension theorems we saw previously. \n",
    "\n",
    "If you recall, we built machinery that worked on $\\sigma$-algebras by building machinery on much simpler families of sets (such as algebras), and then simply argued that the machinery also, by construction *had* to work on the $\\sigma$-generated algebra, too. Here, we're going to take existing machinery that works on a measure space, and show that we can take arbitrary subsets of the event space $\\Omega$ and use it to produce new measurable spaces. \n",
    "\n",
    "Let's give this idea a go:\n",
    "\n",
    "````{prf:corollary} Defining a measure by restriction\n",
    "Suppose that $(\\Omega, \\mathcal F, \\mu)$ is a measure space, and let:\n",
    "1. $\\{F_n\\}_{n \\in \\mathbb N} \\subseteq \\mathcal F$ is a set of disjoint events,\n",
    "2. $F = \\bigsqcup_{n \\in \\mathbb N} F_n$, and\n",
    "3. $f \\in m\\mathcal F$ is a $\\mu$-integrable function.\n",
    "\n",
    "Then:\n",
    "```{math}\n",
    "    \\sum_{n = 1}^\\infty \\int_{F_n}f \\,\\text d \\mu = \\int_F f\\,\\text d \\mu.\n",
    "```\n",
    "\n",
    "Further, if $f \\geq 0$, and for any $A \\in \\mathcal F$ s.t. $A \\subseteq F$, then $\\nu(A) = \\int_A f\\,\\text d\\mu$ defines a measure on $(F, \\mathcal F_F)$, where:\n",
    "```{math}\n",
    "    \\mathcal F_F \\triangleq \\{A \\subseteq F : A \\in \\mathcal F\\}.\n",
    "```\n",
    "````\n",
    "````{prf:proof}\n",
    "Define $f_m \\triangleq f \\mathbb 1_{\\left\\{\\bigsqcup_{n \\in [m]}F_n\\right\\}}$, and let $f_F \\triangleq f\\mathbb 1_{\\{F\\}}$. Then:\n",
    "1. $f_m \\xrightarrow[n \\rightarrow \\infty]{} f_F$,\n",
    "2. $|f_m| \\leq f$ for all $m \\in \\mathbb N$ by construction since $F_m \\subseteq F$, and\n",
    "3. $\\int |f|\\,\\text d \\mu < \\infty$, since by supposition, $f$ is $\\mu$-integrable.\n",
    "\n",
    "Then by the Dominated Convergence {prf:ref}`mt:int:props:conv:dct`:\n",
    "```{math}\n",
    "    \\int_F f\\,\\text d \\mu = \\int f_F \\,\\text d \\mu &\\equiv \\int \\lim_{m \\rightarrow \\infty}f \\mathbb 1_{\\left\\{\\bigsqcup_{n \\in [m]}F_n\\right\\}}\\,\\text d\\mu \\\\\n",
    "    &= \\lim_{m \\rightarrow \\infty}\\int_{\\bigsqcup_{n \\in [m]}F_n} f \\,\\text d \\mu,\\,\\,\\,\\,\\text{DCT}\\\\\n",
    "    &= \\lim_{m \\rightarrow \\infty}\\sum_{n \\in [m]}\\int_{F_n}f \\,\\text d \\mu,\\,\\,\\,\\,F_m\\text{ are disjoint} \\\\\n",
    "    &= \\sum_{n = 1}^\\infty \\int_{F_m} f \\,\\text d \\mu.\n",
    "```\n",
    "The second to last result follows by noting that $\\int_{\\bigsqcup_{n \\in [m]}F_n}f\\,\\text d\\mu = \\int \\sum_{n \\in [m]}\\mathbb 1_{\\{F_n\\}}f\\,\\text d\\mu$ by the disjointness of $\\{F_m\\}$.\n",
    "\n",
    "Then by construction, $\\nu$ is countably additive.\n",
    "\n",
    "If further $f \\geq 0$, then $\\nu \\geq 0$ by construction, indicating that $\\nu$ is a measure since it is countably additive and non-negative. \n",
    "\n",
    "We can repeat this argument for any $A \\subseteq F$ and a countably additive disjoint sequence of events $\\{A_n\\}$ whose union is $A$ to obtain that the desired result holds for any $A \\in \\mathcal F_F$.\n",
    "\n",
    "To see that $(F, \\mathcal F_F)$ is a measurable space, all that's left is to show that $\\mathcal F_F$ is a $\\sigma$-algebra on $F$:\n",
    "\n",
    "1\\. Contains $F$: Since $F \\in \\mathcal F$ and $F \\subseteq F$, then $F \\in \\mathcal F_F$ by definition.\n",
    "\n",
    "2\\. Closed under complements: Suppose that $A \\in \\mathcal F_F$.\n",
    "\n",
    "Define $A_F^c = F \\setminus A \\equiv F \\cap A^c \\subseteq F$ ($A_F^c$ is the complement of $A$ in $F$, and $A^c$ is the complement of $A$ in $\\Omega$). \n",
    "\n",
    "Notice that as $F, A^c \\in \\mathcal F$, that $A_F^c \\in \\mathcal F$, as $\\mathcal F$ is a $\\sigma$-algebra (and hence closed under intersections and complements). \n",
    "\n",
    "Since $F \\cap A^c \\subseteq F$, then $A_F^c = F \\cap A^c \\in \\mathcal F_F$, by definition. \n",
    "\n",
    "3\\. Closed under countable unions: Suppose that $\\{A_n\\} \\subseteq \\mathcal F_F$ is a disjoint sequence of sets.\n",
    "\n",
    "Then $A = \\bigsqcup_n A_n \\subseteq F$, because element-wise, each $A_n \\subseteq F$, and hence the union cannot be $\\supset F$. \n",
    "\n",
    "Since $\\mathcal F$ was a $\\sigma$-algebra, then $A \\in \\mathcal F$, and $A \\subseteq F$.\n",
    "\n",
    "Then $A \\in \\mathcal F_F$, by definition.\n",
    "````\n",
    "\n",
    "## Change of variables\n",
    "\n",
    "Just because we showed that you *can* calculate all the integrals we have discussed thus far, doesn't mean we *want to*. The reason that we have introduced all this new notation, which might feel cumbersome at first, is that it will ultimately make your understanding of random variables and concepts deriving from all the things we've discussed thus far a *lot* easier to wrap your head around. Plainly, the expressions just happen to be a lot simpler, and the rules easier to follow. \n",
    "\n",
    "However, when you actually need to arrive at a numerical solution to an integral, it's typically a lot easier to use the rules of Riemann integration that you've learned through Calculus than it is to use rules like {prf:ref}`mt:int:basics:bounded_int`, {prf:ref}`mt:int:basics:nn:int_def`, or {prf:ref}`mt:int:basics:muint:int`. So, ideally, we will be able to benefit from the conceptual niceties of the measure-theoretic integration intuition that we've developed, but *still* be able to calculate these things numerically in practice. This is done via the *change of variables*, where we *change* the sets we are integrating over from one set to another, using a measurable function:\n",
    "\n",
    "````{prf:lemma} Change of variables\n",
    ":label: mt:int:props:cov\n",
    "Suppose that $(\\Omega, \\mathcal F, \\mu)$ is a measure space, and that $(S, \\Sigma)$ and $(\\mathbb R, \\mathcal R)$ are measurable spaces, wnere $X \\in m(\\mathcal F, \\Sigma)$ and $f \\in m(\\Sigma, \\mathcal R)$ are random variables, and either:\n",
    "1. $f \\geq 0$, or\n",
    "2. $f(X)$ is $\\mu$-integrable.\n",
    "\n",
    "Then with $X_*\\mu = \\mu \\circ X^{-1} : S \\rightarrow \\bar{\\mathbb R}_{\\geq 0}$, and $X(\\Omega) \\triangleq \\{X(\\omega) : \\omega \\in \\Omega\\}$, the *pushforward measure* of $\\mu$ ({prf:ref}`mt:intro:rvs:pushforward`):\n",
    "```{math}\n",
    "    \\int_\\Omega f(X)\\,\\text d \\mu = \\int_{X(\\Omega)} f\\, \\text d\\left(X_*\\mu\\right) = \\int_Sf\\,\\text d \\left(X_*\\mu\\right).\n",
    "```\n",
    "````\n",
    "\n",
    "So, what does this formula let us do? What this formula allows is that we can take a measurable function like $X$, we can compute functions of this measurable function $f(X)$, and then can compute integrals of $f(X)$ using *not* the space upon which $X$ was defined, but on the space upon which $f$ is defined. If the codomain, for instance, is a Riemann space (e.g., $S = \\mathbb R^d$), then we have it really nice: we can use all of the rules we learned in Riemann calculus (the traditional approach to single and multivariable introductory calculus courses). This is called a *change of variables* because we are *changing* from integrating over $\\Omega$ to $X(\\Omega)$ using the pushforward measure $X_*\\mu$. \n",
    "\n",
    "For now, let's work on proving this result. We'll do it in $5$ steps, using a similar approach to what we did when we first learned about integration in {numref}`mt:int:basics`, where we build up the equality from indicators, to simple functions, to bounded functions, to non-negative functions, to $\\mu$-integrable functions. Throughout the below proof, we will repeatedly use the fact that the pushforward measure is a measure, {prf:ref}`mt:intro:rvs:pushforward_is_meas`. This means that measurable functions $f \\in m(\\Sigma, \\mathcal R)$ will be equipped with all of the niceties that we learned about in the preceding chapter {numref}`mt:int:basics` on integration:\n",
    "\n",
    "````{prf:proof}\n",
    "1\\. Indicator functions: Suppose that $B \\in \\Sigma$, and $f \\triangleq \\mathbb 1_{\\{B\\}}(s)$. Then:\n",
    "```{math}\n",
    "    \\int_\\Omega \\mathbb 1_{\\{B\\}}(X) \\,\\text d \\mu &= \\mu(X \\in B) \\equiv \\mu \\circ X^{-1}(B) \\\\\n",
    "    &= X_*\\mu(B) \\\\\n",
    "    &= \\int_{X(\\Omega)} \\mathbb 1_{\\{B\\}}\\,\\text d\\left(X_*\\mu\\right),\n",
    "```\n",
    "Where in the final line, we use that $f \\in m(\\Sigma, \\mathcal R)$, the definition of a pushforward measure, {prf:ref}`mt:intro:rvs:pushforward`, and the definition of the integral of an indicator with respect to a measure, {prf:ref}`mt:int:basics:int:simplefn` (noting that an indicator is a simple function).\n",
    "\n",
    "2\\. Simple functions: Suppose that $\\{B_n\\}_{n \\in [m]} \\subseteq \\Sigma$ for $m \\in \\mathbb N$, and $\\{\\alpha_n\\}_{n \\in [m]} \\subseteq \\mathbb R$, where $\\{B_n\\}_{n \\in [m]}$ are disjoint.\n",
    "\n",
    "Define $f(s) \\triangleq \\sum_{n \\in [m]}\\alpha_n\\mathbb 1_{\\{B_n\\}}(s)$ to be a simple function. Then:\n",
    "```{math}\n",
    "    \\int_\\Omega f(X) \\,\\text d \\mu &= \\int_{\\Omega}\\sum_{n \\in [m]}\\alpha_n\\mathbb 1_{\\{B_n\\}}(X)\\,\\text d \\mu \\\\\n",
    "    &= \\sum_{n \\in [m]}\\int_{\\Omega}\\alpha_n\\mathbb 1_{\\{B_n\\}}(X)\\,\\text d \\mu,\n",
    "```\n",
    "Which follows since the sum of simple functions is simple by {prf:ref}`mt:int:basics:int:prop:sum_simple_fn_simple`. Continuing and using the result from 1.:\n",
    "```{math}\n",
    "    \\int_\\Omega f(X) \\,\\text d \\mu &= \\sum_{n \\in [m]}\\int_{X(\\Omega)} \\alpha_n\\mathbb 1_{\\{B_n\\}}\\,\\text d\\left(X_*\\mu\\right) \\\\\n",
    "    &= \\int_{X(\\Omega)}\\sum_{n \\in [m]}\\alpha_n\\mathbb 1_{\\{B_n\\}}\\,\\text d\\left(X_*\\mu\\right),\\,\\,\\,\\,\\text{Sum of simple fns is simple} \\\\\n",
    "    &= \\int_{X(\\Omega)}f\\,\\text d \\left(X_*\\mu\\right).\n",
    "```\n",
    "Which follows since by {prf:ref}`mt:int:basics:int:prop:sum_simple_fn_simple` and that the pushforward measure is a measure, {prf:ref}`mt:intro:rvs:pushforward`.\n",
    "\n",
    "3\\. Non-negative functions: Suppose $f \\geq 0$, and define:\n",
    "```{math}\n",
    "    f_n(x) \\triangleq \\frac{\\lfloor 2^n f(x)\\rfloor}{2^n}\\wedge n.\n",
    "```\n",
    "Intuitively, $f_n(x)$ is $f(x)$ rounded off to the nearest $\\frac{1}{2^n}$ for a given $x$, and is further upper-bounded by $n$. \n",
    "\n",
    "Note that each $f_n(x)$ is simple because with an upper bound of $n$, there are finitely many ways to round off the value $f_n(x)$ (taking values in $[0, n]$) to the nearest $\\frac{1}{2^n}$ (there are $2^n n$ possible ways to do this).\n",
    "\n",
    "Further, note that $f_n \\uparrow f$ as $n \\rightarrow \\infty$. By definition, $f_n \\geq 0$, and by construction, since $f_n \\uparrow f$ as $n \\rightarrow \\infty$, then $f_n(X) \\uparrow f(X)$ as $n \\rightarrow \\infty$ absolutely (and certainly also $a.e.$). Then by the MCT {prf:ref}`mt:int:props:conv:mct`:\n",
    "```{math}\n",
    "    \\int_\\Omega f(X) \\,\\text d \\mu &= \\lim_{n \\rightarrow \\infty}\\int_\\Omega f_n(X)\\,\\text d \\mu \\\\\n",
    "    &= \\lim_{n \\rightarrow \\infty}\\int_{X(\\Omega)}f_n\\,\\text d \\left(X_*\\mu\\right),\\,\\,\\,\\,\\text{Result from 2.} \\\\\n",
    "    &= \\int_{X(\\Omega)}\\lim_{n \\rightarrow \\infty}f_n\\,\\text d \\left(X_*\\mu\\right),\\,\\,\\,\\,\\text{MCT, as }f_n \\uparrow f, f_n \\geq 0 \\\\\n",
    "    &= \\int_{X(\\Omega)}f \\,\\text d \\left(X_*\\mu\\right).\n",
    "```\n",
    "\n",
    "4\\. Integrable functions: Write $f(x) = f^+(x) - f^-(x)$, where $f^+(x) = \\wedge 0$, and $f^-(x) = (-f(x)) \\wedge 0$, as-per {prf:ref}`mt:int:basics:muint:int`.\n",
    "\n",
    "Then since $f(X)$ is $\\mu$-integrable, both $f^+(X)$ and $f^-(X)$ are $\\mu$-integrable, by Equation {eq}`mt:int:basics:muint:helper`.\n",
    "\n",
    "Direct application of {prf:ref}`mt:int:basics:muint:int` gives:\n",
    "```{math}\n",
    "    \\int_\\Omega f(X) \\,\\text d \\mu = \\int_\\Omega f^+(X) \\,\\text d \\mu - \\int_\\Omega f^-(X) \\,\\text d \\mu.\n",
    "```\n",
    "Note further that $f^+, f^- \\geq 0$. Then by 3.:\n",
    "```{math}\n",
    "    \\int_\\Omega f^+(X) \\,\\text d \\mu - \\int_\\Omega f^-(X) \\,\\text d \\mu &= \\int_{X(\\Omega)}f^+ \\,\\text d \\left(X_*\\mu\\right) - \\int_{X(\\Omega)}f^- \\,\\text d \\left(X_*\\mu\\right) \\\\\n",
    "    &= \\int_{X(\\Omega)}f \\,\\text d \\left(X_*\\mu\\right),\n",
    "```\n",
    "Where in the final line, we used that $f$ is a measurable function with domain $(S, \\Sigma)$ and codomain $(\\mathbb R, \\mathcal R)$, {prf:ref}`mt:int:basics:muint:int`, and the definition of a pushforward measure {prf:ref}`mt:intro:rvs:pushforward`. \n",
    "````\n",
    "\n",
    "As an important remark, notice that we didn't *explicitly* show the right-most equality, but this turns out to be pretty easy:\n",
    "````{prf:remark}\n",
    "Note that in the change of variables formula, the following two are equivalent, which we did not explicitly prove above:\n",
    "```{math}\n",
    "\\int_{X(\\Omega)} f\\, \\text d\\left(X_*\\mu\\right) &= \\int_{S} f\\, \\text d\\left(X_*\\mu\\right).\n",
    "```\n",
    "This is because for any $\\omega \\not \\in X(\\Omega)$, $X^{-1}: \\omega \\mapsto \\varnothing$. Noting that $X_*\\mu$ is a measure, and hence the measure of the empty set is $0$, we can just as easily write:\n",
    "```{math}\n",
    "\\int_{S \\setminus X(\\Omega)} f\\, \\text d\\left(X_*\\mu\\right) &= \\int_{\\omega \\in S \\setminus X(\\Omega)} f\\, \\text d\\left(\\mu\\circ X^{-1}\\right) \\\\\n",
    "&= \\int_{\\omega \\in S \\setminus X(\\Omega)} f\\, \\text d\\left(\\mu(\\varnothing)\\right) \\\\\n",
    "&= 0.\n",
    "```\n",
    "as the right-most quantity is $0$. Therefore:\n",
    "\n",
    "```{math}\n",
    "\\int_{X(\\Omega)} f\\, \\text d\\left(X_*\\mu\\right) &= \n",
    "\\int_{S} f\\, \\text d\\left(X_*\\mu\\right).\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-tampa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-society",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
